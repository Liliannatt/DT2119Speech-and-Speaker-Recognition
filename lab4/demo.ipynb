{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yixu/Tools/anaconda3/envs/speech-lab4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.transforms import MelSpectrogram, FrequencyMasking, TimeMasking\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from lab4_proto import *\n",
    "from lab4_main import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Representing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 'Hello World' -> Integers: [9, 6, 13, 13, 16, 1, 24, 16, 19, 13, 5] -> Back to text: 'hello_world'\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello World\"\n",
    "int_list = strToInt(text)\n",
    "result_text = intToStr(int_list)\n",
    "print(f\"Original text: '{text}' -> Integers: {int_list} -> Back to text: '{result_text}'\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 verify with example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.load('lab4_example.pt')\n",
    "inputs = example['data']\n",
    "spectrograms, labels, input_lengths, label_lengths = dataProcessing(inputs, test_audio_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_spectrograms = example['spectrograms']\n",
    "expected_labels = example['labels'].long() \n",
    "expected_input_lengths = example['input_lengths']\n",
    "expected_label_lengths = example['label_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms match: True\n",
      "Labels match: True\n",
      "Input lengths match: True\n",
      "Label lengths match: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Spectrograms match:\", torch.allclose(spectrograms, expected_spectrograms, atol=1e-7))\n",
    "print(\"Labels match:\", torch.equal(labels, expected_labels))\n",
    "print(\"Input lengths match:\", input_lengths == expected_input_lengths)\n",
    "print(\"Label lengths match:\", label_lengths == expected_label_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train the model and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 13:10:33.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mLoad pre-trained model from \"checkpoints/epoch-19-wer-0.479.pt\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Model Parameters 23311869\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(7)\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\".\", url='train-clean-100', download=True)\n",
    "val_dataset = torchaudio.datasets.LIBRISPEECH(\".\", url='dev-clean', download=True)\n",
    "test_dataset = torchaudio.datasets.LIBRISPEECH(\".\", url='test-clean', download=True)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                batch_size=hparams['batch_size'],\n",
    "                shuffle=True,\n",
    "                collate_fn=lambda x: dataProcessing(x, train_audio_transform),\n",
    "                **kwargs)\n",
    "\n",
    "val_loader = data.DataLoader(dataset=val_dataset,\n",
    "                batch_size=hparams['batch_size'],\n",
    "                shuffle=True,\n",
    "                collate_fn=lambda x: dataProcessing(x, test_audio_transform),\n",
    "                **kwargs)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                batch_size=hparams['batch_size'],\n",
    "                shuffle=False,\n",
    "                collate_fn=lambda x: dataProcessing(x, test_audio_transform),\n",
    "                **kwargs)\n",
    "\n",
    "model = SpeechRecognitionModel(\n",
    "    hparams['n_cnn_layers'], \n",
    "    hparams['n_rnn_layers'], \n",
    "    hparams['rnn_dim'],\n",
    "    hparams['n_class'], \n",
    "    hparams['n_feats'], \n",
    "    hparams['stride'], \n",
    "    hparams['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "# write log into the file\n",
    "cur_version = datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# logger.info(model)\n",
    "print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "\n",
    "model_path = 'checkpoints/epoch-19-wer-0.479.pt'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "logger.info(f'Load pre-trained model from \"{model_path}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with test set audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavfile: LibriSpeech/test-clean/121/121726/121-121726-0000.flac\n",
      "orginal text: ALSO A POPULAR CONTRIVANCE WHEREBY LOVE MAKING MAY BE SUSPENDED BUT NOT STOPPED DURING THE PICNIC SEASON\n",
      "predicted text: ['al_so_a_populocand_drivans_wherm_i_nove_makin_may_bes_suspended_but_not_stoked_during_the_phicknec_eason']\n"
     ]
    }
   ],
   "source": [
    "original_text = 'ALSO A POPULAR CONTRIVANCE WHEREBY LOVE MAKING MAY BE SUSPENDED BUT NOT STOPPED DURING THE PICNIC SEASON'\n",
    "wavfile = 'LibriSpeech/test-clean/121/121726/121-121726-0000.flac'\n",
    "waveform, sample_rate = torchaudio.load(wavfile, normalize=True)\n",
    "resample_rate = 16000\n",
    "if sample_rate != resample_rate:\n",
    "    resampler = T.Resample(orig_freq=sample_rate, new_freq=resample_rate)\n",
    "    waveform = resampler(waveform)\n",
    "spectrogram = test_audio_transform(waveform)\n",
    "input = torch.unsqueeze(spectrogram,dim=0).to(device)\n",
    "output = model(input)\n",
    "text = greedyDecoder(output)\n",
    "print(f'wavfile: {wavfile}')\n",
    "print(f'orginal text: {original_text}')\n",
    "print(f'predicted text: {text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with recorded audio with reading the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavfile: TestAudios/demo2.m4a\n",
      "orginal text: ALSO A POPULAR CONTRIVANCE WHEREBY LOVE MAKING MAY BE SUSPENDED BUT NOT STOPPED DURING THE PICNIC SEASON\n",
      "predicted text: ['al_sapocnacunge_hrer_then_speared_by_lofe_making_ma_besaspendingt_bu_nastob_durin_of_pi_pick_seso_']\n"
     ]
    }
   ],
   "source": [
    "original_text = 'ALSO A POPULAR CONTRIVANCE WHEREBY LOVE MAKING MAY BE SUSPENDED BUT NOT STOPPED DURING THE PICNIC SEASON'\n",
    "wavfile = 'TestAudios/demo2.m4a'\n",
    "waveform, sample_rate = torchaudio.load(wavfile, normalize=True)\n",
    "resample_rate = 16000\n",
    "if sample_rate != resample_rate:\n",
    "    resampler = T.Resample(orig_freq=sample_rate, new_freq=resample_rate)\n",
    "    waveform = resampler(waveform)\n",
    "spectrogram = test_audio_transform(waveform)\n",
    "input = torch.unsqueeze(spectrogram,dim=0).to(device)\n",
    "output = model(input)\n",
    "text = greedyDecoder(output)\n",
    "print(f'wavfile: {wavfile}')\n",
    "print(f'orginal text: {original_text}')\n",
    "print(f'predicted text: {text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with recorded audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wavfile: TestAudios/demo.m4a\n",
      "orginal text: Should the Royal Family be made to do National Service? Vote in our poll as minister refuses to rule out Prince\n",
      "predicted text: ['tud_borbo_only_bein_might_two_motualof_cervis_bo_tie_alrpo_as_mes_thrne_retusa_cina_alpre']\n"
     ]
    }
   ],
   "source": [
    "original_text = \"Should the Royal Family be made to do National Service? Vote in our poll as minister refuses to rule out Prince\"\n",
    "wavfile = 'TestAudios/demo.m4a'\n",
    "waveform, sample_rate = torchaudio.load(wavfile, normalize=True)\n",
    "resample_rate = 16000\n",
    "if sample_rate != resample_rate:\n",
    "    resampler = T.Resample(orig_freq=sample_rate, new_freq=resample_rate)\n",
    "    waveform = resampler(waveform)\n",
    "spectrogram = test_audio_transform(waveform)\n",
    "input = torch.unsqueeze(spectrogram,dim=0).to(device)\n",
    "output = model(input)\n",
    "text = greedyDecoder(output)\n",
    "print(f'wavfile: {wavfile}')\n",
    "print(f'orginal text: {original_text}')\n",
    "print(f'predicted text: {text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 13:18:14.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlab4_main\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1m\n",
      "evaluating…\u001b[0m\n",
      "100%|██████████| 82/82 [41:59<00:00, 30.72s/it]\n",
      "\u001b[32m2024-05-28 14:00:14.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlab4_main\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m253\u001b[0m - \u001b[1mTest set: Average loss: 0.4941, Average CER: 0.1500 Average WER: 0.4597\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not use language model, avg_cer=0.150, avg_wer=0.460\n"
     ]
    }
   ],
   "source": [
    "use_language_model = False\n",
    "\n",
    "avg_cer, avg_wer = test(model, device, test_loader, criterion, -1, use_language_model)\n",
    "if use_language_model:\n",
    "    print(f\"Use language model (alpha={alpha}, beta={beta}), avg_cer={avg_cer:.3f}, avg_wer={avg_wer:.3f}\")\n",
    "else:\n",
    "    print(f\"Not use language model, avg_cer={avg_cer:.3f}, avg_wer={avg_wer:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with language model:\n",
    "alpha = 0.4\n",
    "beta = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-28 14:04:36.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlab4_main\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1m\n",
      "evaluating…\u001b[0m\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Unigrams and labels don't seem to agree.\n",
      "Reading /raid/yixu/Projects/Speech/lab4/wiki-interpolate.3gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "100%|██████████| 82/82 [37:02<00:00, 27.10s/it]\n",
      "\u001b[32m2024-05-28 14:41:39.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlab4_main\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m253\u001b[0m - \u001b[1mTest set: Average loss: 0.4941, Average CER: 0.1141 Average WER: 0.2835\n",
      "\u001b[0m\n",
      "\u001b[32m2024-05-28 14:41:39.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mUse language model (alpha=0.4, beta=0.0), avg_cer=0.114, avg_wer=0.283\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_language_model = True\n",
    "alpha = 0.4\n",
    "beta = 0.0\n",
    "\n",
    "avg_cer, avg_wer = test(model, device, test_loader, criterion, -1, use_language_model, alpha, beta)\n",
    "if use_language_model:\n",
    "    logger.info(f\"Use language model (alpha={alpha}, beta={beta}), avg_cer={avg_cer:.3f}, avg_wer={avg_wer:.3f}\")\n",
    "else:\n",
    "    logger.info(f\"Not use language model, avg_cer={avg_cer:.3f}, avg_wer={avg_wer:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 Tuning the language model weights\n",
    "Grid search results. Best pair: alpha = 0.4, beta = 0.0\n",
    "| Alpha | Beta | WER |\n",
    "|-------|------|-------------|\n",
    "| 0.0   | 0.0  | 0.4037      |\n",
    "| 0.0   | 0.2  | 0.4071      |\n",
    "| 0.0   | 0.4  | 0.4155      |\n",
    "| 0.0   | 0.6  | 0.4171      |\n",
    "| 0.0   | 0.8  | 0.4228      |\n",
    "| 0.0   | 1.0  | 0.4282      |\n",
    "| 0.2   | 0.0  | 0.3092      |\n",
    "| 0.2   | 0.2  | 0.3893      |\n",
    "| 0.2   | 0.4  | 0.4115      |\n",
    "| 0.2   | 0.6  | 0.4152      |\n",
    "| 0.2   | 0.8  | 0.4219      |\n",
    "| 0.2   | 1.0  | 0.4278      |\n",
    "| 0.4   | 0.0  | 0.2913      |\n",
    "| 0.4   | 0.2  | 0.3727      |\n",
    "| 0.4   | 0.4  | 0.4097      |\n",
    "| 0.4   | 0.6  | 0.4177      |\n",
    "| 0.4   | 0.8  | 0.4217      |\n",
    "| 0.4   | 1.0  | 0.4281      |\n",
    "| 0.6   | 0.0  | 0.2979      |\n",
    "| 0.6   | 0.2  | 0.3588      |\n",
    "| 0.6   | 0.4  | 0.4074      |\n",
    "| 0.6   | 0.6  | 0.4148      |\n",
    "| 0.6   | 0.8  | 0.4226      |\n",
    "| 0.6   | 1.0  | 0.4270      |\n",
    "| 0.8   | 0.0  | 0.3290      |\n",
    "| 0.8   | 0.2  | 0.3478      |\n",
    "| 0.8   | 0.4  | 0.4044      |\n",
    "| 0.8   | 0.6  | 0.4163      |\n",
    "| 0.8   | 0.8  | 0.4227      |\n",
    "| 0.8   | 1.0  | 0.4283      |\n",
    "| 1.0   | 0.0  | 0.3874      |\n",
    "| 1.0   | 0.2  | 0.3373      |\n",
    "| 1.0   | 0.4  | 0.4026      |\n",
    "| 1.0   | 0.6  | 0.4155      |\n",
    "| 1.0   | 0.8  | 0.4228      |\n",
    "| 1.0   | 1.0  | 0.4275      |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-lab4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
